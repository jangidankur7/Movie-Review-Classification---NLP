{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Multinomial Event Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [ \"This was an awesome movie\",\n",
    "     \"Great movie!Liked a lot\",\n",
    "     \"Happy Ending movie\",\n",
    "     \"Worst movie ever\",\n",
    "     \"Surely a peice of shit for us\"\n",
    "    ]\n",
    "\n",
    "y = [1,1,1,0,0]   # 1:Positive review 2:Negetive review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = [\"I was happy and happy and aI loved the acting in the movie\",\n",
    "         \"This was a shit of peice\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cleaning :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clean_function as cf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_clean = [cf.getCleanReview(i) for i in x]   #### List comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt_clean = [cf.getCleanReview(i) for i in x_test]   #### List comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['awesom movi', 'great movi like lot', 'happi end movi', 'worst movi ever', 'sure peic shit us']\n"
     ]
    }
   ],
   "source": [
    "print(x_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['happi happi ai love act movi', 'shit peic']\n"
     ]
    }
   ],
   "source": [
    "print(xt_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Vectorization  (just for knowledge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(ngram_range=(1,2))\n",
    "x_vec = cv.fit_transform(x_clean).toarray()\n",
    "\n",
    "print(x_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 24)\n"
     ]
    }
   ],
   "source": [
    "print(x_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['awesom', 'awesom movi', 'end', 'end movi', 'ever', 'great', 'great movi', 'happi', 'happi end', 'like', 'like lot', 'lot', 'movi', 'movi ever', 'movi like', 'peic', 'peic shit', 'shit', 'shit us', 'sure', 'sure peic', 'us', 'worst', 'worst movi']\n"
     ]
    }
   ],
   "source": [
    "print(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 2 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0]]\n",
      "(2, 24)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['awesom',\n",
       " 'awesom movi',\n",
       " 'end',\n",
       " 'end movi',\n",
       " 'ever',\n",
       " 'great',\n",
       " 'great movi',\n",
       " 'happi',\n",
       " 'happi end',\n",
       " 'like',\n",
       " 'like lot',\n",
       " 'lot',\n",
       " 'movi',\n",
       " 'movi ever',\n",
       " 'movi like',\n",
       " 'peic',\n",
       " 'peic shit',\n",
       " 'shit',\n",
       " 'shit us',\n",
       " 'sure',\n",
       " 'sure peic',\n",
       " 'us',\n",
       " 'worst',\n",
       " 'worst movi']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Vectorization on the test_set \n",
    "xt_vec = cv.transform(xt_clean).toarray()\n",
    "\n",
    "print(xt_vec)\n",
    "print(xt_vec.shape)\n",
    "\n",
    "cv.get_feature_names()## As we can see, features have changed and we DONT want that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we dont want to learn parameters from test data. So we need train data parameters , so at second feature extraction, we wrote transform NOT fit_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB,GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB()\n"
     ]
    }
   ],
   "source": [
    "print(mnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 24)\n"
     ]
    }
   ],
   "source": [
    "print(x_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Training :\n",
    "\n",
    "mnb.fit(x_vec,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "mnb.score(x_vec,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Prediction:\n",
    "mnb.predict(xt_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09580081, 0.90419919],\n",
       "       [0.75784753, 0.24215247]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Probablity of lying on which class ?\n",
    "\n",
    "mnb.predict_proba(xt_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prob of lying on class 0 vs class 1 for both test reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclude :\n",
    "- From Output to : mnb.predict(xt_vec) = array([1, 0]) we say that:\n",
    "    - x_test = [\"I was happy and happy and aI loved the acting in the movie\",\n",
    "         \"This was a shit of peice\"]\n",
    "         \n",
    "     - X training Data:\n",
    "     x = [ \"This was an awesome movie\",\n",
    "     \"Great movie!Liked a lot\",\n",
    "     \"Happy Ending movie\",\n",
    "     \"Worst movie ever\",\n",
    "     \"Surely a peice of shit for us\"\n",
    "    ]\n",
    "\n",
    "    - y = [1,1,1,0,0]   # 1:Positive review 2:Negetive review\n",
    "    \n",
    "    \n",
    "    - We trained our system with making sys learn which comments are +ve and which are -ve.\n",
    "    - So while we gave x_test it searched train data and searched for words which corrosponds to which type of review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flaw :\n",
    "- Sent_1 : Moie I saw was bad\n",
    "- Sent_2 : Movie I saw was not Bad\n",
    "\n",
    "- In both cases,sys will pridect review as -ve as in Concept of Bag  of words , order is not imortant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remedy :\n",
    "- We can use ngram_range to enhance quality and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multivariate Burnoulli Event Model Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb = BernoulliNB(binarize=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "binarize = 0.0 means all avalues above 0 will be treated as 1 and below 0 will be treated as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.naive_bayes.BernoulliNB'>\n"
     ]
    }
   ],
   "source": [
    "print(bnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.fit(x_vec,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01694099, 0.98305901],\n",
       "       [0.68806684, 0.31193316]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.predict_proba(xt_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Multivariate model - it depends on frequncy of word occuring in sentence \n",
    "\n",
    "but for Burnoulii- it depends whether word is present or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.predict(xt_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.score(x_vec,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
